FROM ubuntu:16.04

LABEL maintainer=Bharath “bharath.jayachandran@live.com”

USER root

# base installs
RUN apt-get update && apt-get install -y \
software-properties-common \
wget \
vim \
git \
bzip2 

#install java 8
RUN add-apt-repository ppa:webupd8team/java
RUN apt-get update
RUN echo debconf shared/accepted-oracle-license-v1-1 select true | debconf-set-selections
RUN apt-get -y install oracle-java8-installer -y

#install spark
RUN wget http://www-eu.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz
RUN tar xvf spark-2.3.0-bin-hadoop2.7.tgz -C ~/ && rm /spark-2.3.0-bin-hadoop2.7.tgz
RUN mv ~/spark-2.3.0-bin-hadoop2.7 ~/spark

#install anaconda
RUN cd ~ && wget https://repo.anaconda.com/archive/Anaconda3-5.1.0-Linux-x86_64.sh
RUN bash ~/Anaconda3-5.1.0-Linux-x86_64.sh -b -p /root/anaconda
ENV PATH /root/anaconda/bin:$PATH

#ENV SPARK
ENV PYSPARK_PYTHON python3
ENV PYSPARK_DRIVER_PYTHON jupyter
ENV PYSPARK_DRIVER_PYTHON_OPTS "notebook --no-browser --port=8888 --allow-root --ip='0.0.0.0'"
ENV PATH /root/spark/bin:$PATH

# expose jupyter notebook port 8888
EXPOSE 8888 4040

# make directory for notebooks
RUN mkdir /root/jup

# change dir
WORKDIR /root/jup

# default command

CMD ["pyspark"]

